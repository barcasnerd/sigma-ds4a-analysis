{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Final model implementation.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNuGO6PDdSOqvpFcnUpO9Ng"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"LGge-KzRSrkz"},"source":["# Final model implementation\n","\n","This notebook will be implemented as .py in Front-end application.\n","The functions below will clean and transform the input text, and will return a DataFrame (3x2) with the three most possible categories and its probability of occurrence."]},{"cell_type":"code","metadata":{"id":"S9WzVj2dSgvd"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split\n","\n","import nltk # imports the natural language toolkit\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize     # Librería para tratamiento de \"Tokens\"\n","import re\n","from spellchecker import SpellChecker"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"egg2VjZbSmf0"},"source":["def model_classifier(loc):\n","    \"\"\"Función para entrar algoritmo de Random Forest\n","    loc = Localización de datos\n","    return:\n","    model: Clasificador entrenado\"\"\"\n","    \n","    # Importar datos\n","    df = pd.read_csv(loc, encoding = 'latin-1' )\n","    df.columns = ['tik_codigo', 'descripcion', 'propietario', 'categoria', 'ans',\n","       'nombre_cliente', 'Linea_Negocio', 'newCategory', 'newDescription']\n","\n","    df.dropna(subset = [\"newDescription\", \"newCategory\"], inplace=True)\n","    df = df.reset_index(drop=True)\n","    documents = df[[\"newDescription\", \"newCategory\"]].copy()\n","\n","    # Creación de variables dependientes e independientes\n","\n","    X = documents.newDescription\n","    y = documents.newCategory\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 19)\n","\n","    # Transformar los datos de texto apoyados en Tf-Idf\n","\n","    tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n","    X_train = tfidf_vectorizer.fit_transform(X_train) \n","    X_test = tfidf_vectorizer.transform(X_test)\n","    \n","    classifier = RandomForestClassifier(max_features='sqrt', n_estimators=1000)\n","    classifier.fit(X_train, y_train)\n","   \n","    return classifier"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pEFLoLZVSoV2"},"source":["def transform_data(loc, data):\n","    \"\"\"Función para transformar datos. Debe ser un arreglo iterable\n","    \n","    loc: Localización del documento\n","    data: Nuevas observaciones\"\"\"\n","    \n","    spell = SpellChecker(language='es')\n","\n","    stop_words = stopwords.words('spanish')\n","    \n","    def stripchars(data):\n","        data = data.lower()\n","        data = data+\" \"\n","        data = data.replace(\"á\",\"a\").replace(\"é\",\"e\").replace(\"í\",\"i\").replace(\"ó\",\"o\").replace(\"ú\",\"u\")\n","        p = re.compile(r'[^\\w\\s\\d]')\n","        p = p.sub(' ', data)\n","        p = re.sub(\" \\d+\", \" \", p)\n","        return p\n","\n","    def remove_stop_words(review):\n","        tokens = word_tokenize(review)  \n","        text_with_no_stop_words = [spell.correction(token) for token in tokens if not token in stop_words]\n","        reformed_sentence = ' '.join(text_with_no_stop_words)\n","        return reformed_sentence\n","    \n","        # Importar datos\n","    df = pd.read_csv(loc, encoding = 'latin-1' )\n","    df.columns = ['tik_codigo', 'descripcion', 'propietario', 'categoria', 'ans',\n","       'nombre_cliente', 'Linea_Negocio', 'newCategory', 'newDescription']\n","\n","    df.dropna(subset = [\"newDescription\", \"newCategory\"], inplace=True)\n","    df = df.reset_index(drop=True)\n","    documents = df[[\"newDescription\", \"newCategory\"]].copy()\n","\n","    # Creación de variables dependientes e independientes\n","\n","    X = documents.newDescription\n","    y = documents.newCategory\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 19)\n","    \n","    vectorizer = TfidfVectorizer(use_idf=True)\n","    vectorizer.fit(X_train)\n","    \n","    data = remove_stop_words(stripchars(data))    \n","    data = vectorizer.transform([data])\n","    \n","    return data "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4zAscQbgSpfi"},"source":["def make_pred(loc, new_data, classifier):\n","    \"\"\"Función para realizar pronósticos\n","    \n","    loc = Localización del del archivo con los datos a analizar\n","    new_data = Nuevos datos a pronósticar\n","    classifier = modelo clasificador entrenado\"\"\"\n","    \n","    categories = ['Nuevo requerimiento', 'Servicios', 'Datos', 'Visor', 'GPS','Funcionalidad', 'Formulario',\n","                  'Reporte', 'Sistema', 'Consultas','App', 'Otros', 'Shape']   \n","    \n","    data = transform_data(loc, new_data)\n","    \n","    if data.getnnz() != 0:\n","        \n","        category = classifier.predict(data)\n","        probabilities = classifier.predict_proba(data)\n","        cat_prob = pd.DataFrame(probabilities,columns=categories).T\n","        cat_prob.columns = [\"Category probability\"]*len(cat_prob.columns)\n","        cat_prob = cat_prob.sort_values(\"Category probability\", axis=0, ascending=False).head(3)\n","    else:\n","        cat_prob = 0\n","        print(\"Especifique mejor la descripción\")\n","    \n","    return cat_prob"],"execution_count":null,"outputs":[]}]}